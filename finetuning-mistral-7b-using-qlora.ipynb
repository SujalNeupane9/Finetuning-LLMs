{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install accelerate peft trl datasets bitsandbytes auto-gptq optimum -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-25T09:55:59.634537Z","iopub.execute_input":"2023-11-25T09:55:59.635196Z","iopub.status.idle":"2023-11-25T09:56:11.995186Z","shell.execute_reply.started":"2023-11-25T09:55:59.635160Z","shell.execute_reply":"2023-11-25T09:56:11.994035Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport datasets\nfrom transformers import AutoTokenizer, AutoModelForCausalLM,GPTQConfig, TrainingArguments\nfrom peft import LoraConfig,prepare_model_for_kbit_training, get_peft_model\nfrom trl import SFTTrainer\n\ndataset = datasets.load_dataset('iamtarun/python_code_instructions_18k_alpaca',split='train')","metadata":{"execution":{"iopub.status.busy":"2023-11-25T09:56:11.997432Z","iopub.execute_input":"2023-11-25T09:56:11.998180Z","iopub.status.idle":"2023-11-25T09:56:19.509692Z","shell.execute_reply.started":"2023-11-25T09:56:11.998141Z","shell.execute_reply":"2023-11-25T09:56:19.508659Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"model_ckpt = \"TheBloke/Mistral-7B-Instruct-v0.1-GPTQ\"\n\ntokenizer = AutoTokenizer.from_pretrained(\n    model_ckpt\n)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2023-11-25T09:56:26.567230Z","iopub.execute_input":"2023-11-25T09:56:26.567618Z","iopub.status.idle":"2023-11-25T09:56:26.711655Z","shell.execute_reply.started":"2023-11-25T09:56:26.567589Z","shell.execute_reply":"2023-11-25T09:56:26.710830Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"quantization_config = GPTQConfig(bits=4,disable_exllama=True,tokenizer=tokenizer)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_ckpt,\n    quantization_config=quantization_config,\n    device_map='auto')\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\nmodel.gradient_checkpointing_enable()\nmodel = prepare_model_for_kbit_training(model)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T09:56:28.730753Z","iopub.execute_input":"2023-11-25T09:56:28.731159Z","iopub.status.idle":"2023-11-25T09:57:04.115897Z","shell.execute_reply.started":"2023-11-25T09:56:28.731127Z","shell.execute_reply":"2023-11-25T09:57:04.114812Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\nYou passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute and has already quantized weights. However, loading attributes (e.g. use_exllama, exllama_config, use_cuda_fp16, max_input_length) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/4.16G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1a4d9d9e2564e7cbafde66a59b26f22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"619df80bb6ca4ca7b3abc7a7703e6d92"}},"metadata":{}}]},{"cell_type":"code","source":"lora_config = LoraConfig(r=16,\n                        lora_alpha=32,\n                        lora_dropout=0.05,\n                        bias='none',\n                        task_type='CAUSAL_LM',\n                        target_modules=[\n                                    \"q_proj\",\n                                    \"k_proj\",\n                                    \"v_proj\",\n                                    \"o_proj\",\n                                    \"gate_proj\",\n                                    \"up_proj\",\n                                    \"down_proj\",\n                                        ]\n)\nmodel = get_peft_model(model,lora_config)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T09:57:11.102719Z","iopub.execute_input":"2023-11-25T09:57:11.103213Z","iopub.status.idle":"2023-11-25T09:57:12.102823Z","shell.execute_reply.started":"2023-11-25T09:57:11.103177Z","shell.execute_reply":"2023-11-25T09:57:12.101988Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(output_dir='.',\n                                 dataloader_drop_last=True,\n                                 save_strategy='epoch',\n                                 num_train_epochs=1,\n                                 logging_steps=100,\n                                 max_steps=1000,\n                                 per_device_train_batch_size=1,\n                                 learning_rate=3e-4,\n                                 lr_scheduler_type='cosine',\n                                 warmup_steps=100,\n                                 fp16=True,\n                                 #gradient_accumulation_steps=2,\n                                 weight_decay=0.05,\n                                 report_to=None,\n                                 run_name='finetuning-mistral-7b')","metadata":{"execution":{"iopub.status.busy":"2023-11-25T09:57:17.481870Z","iopub.execute_input":"2023-11-25T09:57:17.482246Z","iopub.status.idle":"2023-11-25T09:57:17.491072Z","shell.execute_reply.started":"2023-11-25T09:57:17.482216Z","shell.execute_reply":"2023-11-25T09:57:17.490127Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"trainer = SFTTrainer(model=model,\n                    args=training_args,\n                    train_dataset = dataset,\n                    dataset_text_field='prompt',\n                    max_seq_length=1024,\n                    tokenizer=tokenizer,\n                    packing=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T09:57:21.472594Z","iopub.execute_input":"2023-11-25T09:57:21.473010Z","iopub.status.idle":"2023-11-25T09:57:28.101292Z","shell.execute_reply.started":"2023-11-25T09:57:21.472974Z","shell.execute_reply":"2023-11-25T09:57:28.100344Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/19 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d765d4a8df54a39b744a3cb0f8d5c80"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:247: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-11-25T09:57:30.646715Z","iopub.execute_input":"2023-11-25T09:57:30.647143Z","iopub.status.idle":"2023-11-25T10:43:46.399385Z","shell.execute_reply.started":"2023-11-25T09:57:30.647110Z","shell.execute_reply":"2023-11-25T10:43:46.398237Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231125_095759-vvpaud4x</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/neupane9sujal/huggingface/runs/vvpaud4x' target=\"_blank\">finetuning-mistral-7b</a></strong> to <a href='https://wandb.ai/neupane9sujal/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/neupane9sujal/huggingface' target=\"_blank\">https://wandb.ai/neupane9sujal/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/neupane9sujal/huggingface/runs/vvpaud4x' target=\"_blank\">https://wandb.ai/neupane9sujal/huggingface/runs/vvpaud4x</a>"},"metadata":{}},{"name":"stderr","text":"You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1000/1000 45:09, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.687400</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.632500</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.631600</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.625700</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.625000</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.608200</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.598800</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.561600</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.541900</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.549300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1000, training_loss=0.6062065391540528, metrics={'train_runtime': 2775.3909, 'train_samples_per_second': 0.36, 'train_steps_per_second': 0.36, 'total_flos': 218754446622720.0, 'train_loss': 0.6062065391540528, 'epoch': 0.05})"},"metadata":{}}]}]}